{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNHbt+E9bdouPu/gnUrtFqW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sush2059/softwareeng/blob/main/Untitled28.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U__uYrLfDE5n",
        "outputId": "ba72aea9-cc64-4ca5-e68b-3cf7c0a9653b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Headlines saved to 'bbc_headlines.csv'\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "# BBC News Live Page URL\n",
        "URL = \"https://www.bbc.com/news/live/c981p3dxnent\"\n",
        "\n",
        "# Requesting the webpage\n",
        "headers = {'User-Agent': 'Mozilla/5.0'}  # Prevents request blocking\n",
        "response = requests.get(URL, headers=headers)\n",
        "\n",
        "# Check response status\n",
        "if response.status_code == 200:\n",
        "    # Parse HTML\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # Extract headlines from <h1>, <h2>, and <h3> tags\n",
        "    headlines = soup.find_all(['h1', 'h2', 'h3'])\n",
        "\n",
        "    # Store headlines in a list\n",
        "    headline_list = [{\"No.\": i+1, \"Headline\": h.text.strip()} for i, h in enumerate(headlines)]\n",
        "\n",
        "    # Convert to DataFrame\n",
        "    df = pd.DataFrame(headline_list)\n",
        "\n",
        "    # Save to CSV\n",
        "    csv_filename = \"bbc_headlines.csv\"\n",
        "    df.to_csv(csv_filename, index=False, encoding=\"utf-8\")\n",
        "    print(f\"✅ Headlines saved to '{csv_filename}'\")\n",
        "else:\n",
        "    print(\"❌ Failed to retrieve webpage. Status Code:\", response.status_code)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"bbc_headlines.csv\")\n",
        "print(df.head())  # Display first few rows\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-Jc0zL8DPMS",
        "outputId": "291dad62-dbc3-4360-d041-12fbedc5cd85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   No.                                           Headline\n",
            "0    1            Trump pauses US military aid to Ukraine\n",
            "1    2                                            Summary\n",
            "2    3                                     Live Reporting\n",
            "3    4  Ninety-nine drones launched into Ukraine overn...\n",
            "4    5  What has the White House said so far?published...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# BBC News Live Page URL\n",
        "URL = \"https://www.bbc.com/news/live/c981p3dxnent\"\n",
        "\n",
        "# Requesting the webpage\n",
        "headers = {'User-Agent': 'Mozilla/5.0'}  # Prevents request blocking\n",
        "response = requests.get(URL, headers=headers)\n",
        "\n",
        "# Check response status\n",
        "if response.status_code == 200:\n",
        "    # Parse HTML\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # Extract headlines from <h1>, <h2>, and <h3> tags\n",
        "    headlines = soup.find_all(['h1', 'h2', 'h3'])  # Combined into one step\n",
        "\n",
        "    # Display headlines\n",
        "    if headlines:\n",
        "        for i, headline in enumerate(headlines, 1):\n",
        "            print(f\"Headline {i}: {headline.text.strip()}\\n\")\n",
        "    else:\n",
        "        print(\"No headlines found.\")\n",
        "else:\n",
        "    print(\"Failed to retrieve webpage. Status Code:\", response.status_code)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NiLcu8OzHpfh",
        "outputId": "1d9f3faf-4a49-45f6-eac8-f50bcb558272"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Headline 1: Trump pauses US military aid to Ukraine\n",
            "\n",
            "Headline 2: Summary\n",
            "\n",
            "Headline 3: To play this video you need to enable JavaScript in your browser.\n",
            "\n",
            "Headline 4: Live Reporting\n",
            "\n",
            "Headline 5: Europe can manage without US military aid, former Ukrainian minister sayspublished at 07:44 Greenwich Mean Time07:44 GMT\n",
            "\n",
            "Headline 6: Ukraineâs American lifeline blocked once morepublished at 07:32 Greenwich Mean Time07:32 GMT\n",
            "\n",
            "Headline 7: How does US support compare to other nations?published at 07:26 Greenwich Mean Time07:26 GMT\n",
            "\n",
            "Headline 8: Ninety-nine drones launched into Ukraine overnight, air force sayspublished at 07:20 Greenwich Mean Time07:20 GMT\n",
            "\n",
            "Headline 9: What has the White House said so far?published at 07:13 Greenwich Mean Time07:13 GMT\n",
            "\n",
            "Headline 10: The key players we haven't heard from yetpublished at 07:09 Greenwich Mean Time07:09 GMT\n",
            "\n",
            "Headline 11: Can Europe fill gap left by US's pause in military aid?published at 07:00 Greenwich Mean Time07:00 GMT\n",
            "\n",
            "Headline 12: To play this video you need to enable JavaScript in your browser.\n",
            "\n",
            "Headline 13: UK trying to bring Trump and Zelensky back together, officials saypublished at 06:50 Greenwich Mean Time06:50 GMT\n",
            "\n",
            "Headline 14: This major escalation will heap more pressure on Zelenskypublished at 06:43 Greenwich Mean Time06:43 GMT\n",
            "\n",
            "Headline 15: To play this video you need to enable JavaScript in your browser.\n",
            "\n",
            "Headline 16: It's a date that will go down in infamy, says Ukrainian MPpublished at 06:35 Greenwich Mean Time06:35 GMT\n",
            "\n",
            "Headline 17: How foreign policy hawk Marco Rubio's tone evolved on Ukrainepublished at 06:25 Greenwich Mean Time06:25 GMT\n",
            "\n",
            "Headline 18: Trump tariffs on Canada, Mexico and China to come into forcepublished at 05:58 Greenwich Mean Time05:58 GMT\n",
            "\n",
            "Headline 19: How much money has US given to Ukraine?published at 05:38 Greenwich Mean Time05:38 GMT\n",
            "\n",
            "Headline 20: 'It's the Ukrainians who are shedding blood,' Senate Republican sayspublished at 04:46 Greenwich Mean Time04:46 GMT\n",
            "\n",
            "Headline 21: Ex-US envoy says aid pause 'very wrongheaded'published at 03:57 Greenwich Mean Time03:57 GMT\n",
            "\n",
            "Headline 22: Former security director calls Trump's Ukraine aid freeze 'coercive diplomacy'published at 03:31 Greenwich Mean Time03:31 GMT\n",
            "\n",
            "Headline 23: This is not the first timepublished at 03:18 Greenwich Mean Time03:18 GMT\n",
            "\n",
            "Headline 24: Vance: 'Hereâs the problem with the Europeans...'published at 03:11 Greenwich Mean Time03:11 GMT\n",
            "\n",
            "Headline 25: 'The door is open' for resumed peace talks, Vance sayspublished at 02:49 Greenwich Mean Time02:49 GMT\n",
            "\n",
            "Headline 26: Zelensky had 'sense of entitlement' in Oval Office, Vance sayspublished at 02:22 Greenwich Mean Time02:22 GMT\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "import os\n",
        "import subprocess\n",
        "from datetime import datetime\n",
        "\n",
        "# GitHub Repository and Token\n",
        "GITHUB_REPO_URL = \"https://github.com/harika1837/se\"\n",
        "GITHUB_ACCESS_TOKEN = \"your_personal_access_token_here\"\n",
        "\n",
        "# Hacker News URL\n",
        "NEWS_URL = \"https://news.ycombinator.com/\"\n",
        "CSV_FILENAME = \"hacker_news.csv\"\n",
        "\n",
        "def scrape_hacker_news():\n",
        "    response = requests.get(NEWS_URL)\n",
        "    response.raise_for_status()\n",
        "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "    titles = soup.select(\".titleline > a\")\n",
        "    subtexts = soup.select(\".subtext\")\n",
        "\n",
        "    news_data = []\n",
        "    for i in range(min(len(titles), len(subtexts))):\n",
        "        title = titles[i].text\n",
        "        link = titles[i].get(\"href\")\n",
        "        try:\n",
        "            points = int(subtexts[i].select_one(\".score\").text.split()[0])\n",
        "        except AttributeError:\n",
        "            points = 0\n",
        "        news_data.append([title, link, points])\n",
        "\n",
        "    return news_data\n",
        "\n",
        "def save_to_csv(data, filename=CSV_FILENAME):\n",
        "    with open(filename, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
        "        writer = csv.writer(csvfile)\n",
        "        writer.writerow([\"Title\", \"Link\", \"Points\"])\n",
        "        writer.writerows(data)\n",
        "\n",
        "def commit_to_github():\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
        "    commit_message = f\"Update Hacker News data {timestamp}\"\n",
        "\n",
        "    subprocess.run([\"git\", \"config\", \"--global\", \"user.email\", \"hlekkla@gitam.in\"])\n",
        "    subprocess.run([\"git\", \"config\", \"--global\", \"user.name\", \"harika\"])\n",
        "    subprocess.run([\"git\", \"add\", CSV_FILENAME])\n",
        "    subprocess.run([\"git\", \"commit\", \"-m\", commit_message])\n",
        "    subprocess.run([\"git\", \"push\", \"origin\", \"main\"])\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        if not os.path.exists(\".git\"):\n",
        "            subprocess.run([\"git\", \"clone\", GITHUB_REPO_URL, \".\"])\n",
        "            subprocess.run([\"git\", \"remote\", \"set-url\", \"origin\", GITHUB_REPO_URL])\n",
        "\n",
        "        subprocess.run([\"git\", \"pull\", \"origin\", \"main\"])\n",
        "\n",
        "        news_data = scrape_hacker_news()\n",
        "        save_to_csv(news_data)\n",
        "        commit_to_github()\n",
        "\n",
        "        print(\"Successfully scraped, saved, and pushed to GitHub!\")\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error during web scraping: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTrL2k4ET0kh",
        "outputId": "e67dcf59-3104-49b6-c582-3fde5f9528a7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully scraped, saved, and pushed to GitHub!\n"
          ]
        }
      ]
    }
  ]
}